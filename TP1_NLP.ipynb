{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joaoplims/NLP-Projects/blob/main/TP1_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFOvhaaACUia",
        "outputId": "7d1b50ad-44ae-47de-a239-6b1fe46a86c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n",
            "Média das distâncias do cosseno Modelo1: -0.004335553103754178\n",
            "----------- FIM ANALOGIA MODELO modelo 1 -----------\n",
            "Média das distâncias do cosseno para o Modelo2: -0.004335553103754178\n",
            "----------- FIM ANALOGIA MODELO modelo 2 -----------\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim scikit-learn numpy\n",
        "\n",
        "import gensim\n",
        "import requests\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import gensim.downloader as api\n",
        "import requests\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from io import StringIO\n",
        "\n",
        "\n",
        "# Baixar o corpus text8\n",
        "corpus = api.load('text8')\n",
        "\n",
        "# Converter o corpus para uma lista de listas de palavras (sentenças)\n",
        "text8Data = [d for d in corpus]\n",
        "\n",
        "\n",
        "# Função para treinar o modelo\n",
        "def train_model(corpus, size, window, sg, epochs):\n",
        "    model = Word2Vec(corpus, vector_size=size, window=window, sg=sg, epochs=epochs)\n",
        "    model.save(f'model_size{size}_window{window}_sg{sg}_epochs{epochs}.model')\n",
        "    return model\n",
        "\n",
        "# Treinar diversos modelos\n",
        "#model1 = train_model(text8Data, size=100, window=5, sg=0, epochs=5)  # CBOW\n",
        "#model2 = train_model(text8Data, size=200, window=10, sg=1, epochs=10) # Skip-gram\n",
        "\n",
        "# Carregar o modelo salvo\n",
        "model1 = Word2Vec.load('/content/model_size100_window5_sg0_epochs5.model')\n",
        "model1 = Word2Vec.load('/content/model_size200_window10_sg1_epochs10.model')\n",
        "\n",
        "\n",
        "\n",
        "# Função para avaliar o modelo\n",
        "def evaluate_analogy(analogy_file, model):\n",
        "    with open(analogy_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    distances = []\n",
        "    for line in lines:\n",
        "        words = line.split()\n",
        "        if len(words) != 4:\n",
        "            continue\n",
        "\n",
        "        # Check if all words are in the vocabulary before proceeding\n",
        "        if all(word in model.wv for word in words):\n",
        "            vec = model.wv[words[1]] + model.wv[words[0]] - model.wv[words[2]]\n",
        "            expected = model.wv[words[3]]\n",
        "            distance = cosine_similarity([vec], [expected])[0][0]\n",
        "            distances.append(distance)\n",
        "        #else:\n",
        "            # Handle cases where words are not in the vocabulary (e.g., skip or print a message)\n",
        "         #   print(f\"Skipping analogy: {line.strip()} - One or more words not in vocabulary\")\n",
        "\n",
        "    # Return 0 if no analogies were evaluated to avoid division by zero\n",
        "    if not distances:\n",
        "        return 0\n",
        "\n",
        "    return sum(distances) / len(distances)\n",
        "\n",
        "# Avaliar o modelo carregado\n",
        "avg_distance1 = evaluate_analogy('/content/questions-words.txt', model1)\n",
        "print(f'Média das distâncias do cosseno Modelo1: {avg_distance1}')\n",
        "\n",
        "print(\"----------- FIM ANALOGIA MODELO modelo 1 -----------\");\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Avaliar o modelo\n",
        "avg_distance2 = evaluate_analogy('/content/questions-words.txt', model2)\n",
        "print(f'Média das distâncias do cosseno para o Modelo2: {avg_distance2}')\n",
        "\n",
        "print(\"----------- FIM ANALOGIA MODELO modelo 2 -----------\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nkbynxVg0Cd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOb6zvIAM9+5kDYMhU1L3hW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}